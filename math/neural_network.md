---
author: lunar
date: Mon 31 Aug 2020 04:31:25 PM CST
---

## 神经网络模型

神经网络模型，这玩意是机器学习的基础。有关的理论已经发展成了界于数学，计算机科学和神经生物学之间的交叉学科。

### 人工神经元模型

人工神经元有三个基本要素：
1. 一组连接，连接强度由连接上的权值表示，权值为正表示激活，为负表示抑制。
2. 一个求和单元，求取各输入信号的加权和。
3. 一个非线性激活函数，其非线性映射作用并将神经元输出幅度抑制在一定范围内(一般限制在(0,1)或(-1,1)之间)。非常重要，没有非线性激活函数的话，不管有多少层神经网络都只相当于一层神经网络。

用数学表达式即为
$$
v_k = \sum_{j=0}^pw_{kj}x_j, y_k = \varphi(u_k)
$$

$x_0 = -1, w_{k0} = \theta_k$, $\theta_k$即为阈值.

激活函数$\varphi$有以下几种
1. 阈值函数
$$
\varphi(v) = \begin{cases}1, v\ge0\\0,v<0\end{cases}
$$
常称此种神经元为M-P模型.
2. sigmoid函数
$$
\varphi(v) = \frac1{1+\exp(-\alpha v)}
$$

这类函数具有平滑和渐进性, 并保持单调性.

### 网络结构和工作方式

1. 前馈型网络
各神经元接受前一层的输入, 并输出给下一层, 没有反馈. 可以接受多个输入, 但只有一个输出. 
2. 反馈型网络
所有节点都是计算单元, 同时也可以接受输入, 并向外界输出.

### 反向传播算法(Back-Propagation)

神经网络的运作原理是确定清楚了, 但是在每一层, 都需要大量的权值乘以输入.

如何求得一组恰当的权值, 使得网络具有特定的功能成了需要解决的问题.

反向传播算法正是用于解决这个问题.

要求得最佳的权值, 实际上就是为了计算使得输出与期望输出之间的误差最小的权值. 最为方便的是使用**最速下降法**.

从任意一个初始点$W_0$出发, 计算在$W_0$的负梯度方向$-\nabla E(W_0)$, 这是函数在该点下降最快的方向. 只要沿该方向下降一段距离, 达到一个新的点$W_1 = W_0 - \eta\nabla E(W_0)$, $\eta$表示步幅, 有时又称为学习因子, 学习因子不宜过大也不宜过小. 过小会导致学习速度很慢, 过大又会导致产生振荡, 即函数在下降时会直接跨过极小点到达另一个点, 然后又跨回来, 振荡多次后才停在极小点.

不断地迭代这个过程总能找到一个局部极小点.

把理想输出记为$\{T_i^s\}$, 误差的计算公式为
$$
E(W) = \frac12\sum_{i,s}(T_i^s-O_i^s)^2
$$


